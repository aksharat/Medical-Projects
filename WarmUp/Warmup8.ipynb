{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYspoZ1ez5PHrVpE9h5vkd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aksharat/Medical-Projects/blob/main/WarmUp/Warmup8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvTKT4OGBZpx",
        "outputId": "3f204934-7f4b-4f47-d5b8-72997fa8c522"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-14 23:20:11--  http://imgcom.jsrt.or.jp/imgcom/wp-content/uploads/2019/07/autoencoder_img.zip\n",
            "Resolving imgcom.jsrt.or.jp (imgcom.jsrt.or.jp)... 158.199.228.161\n",
            "Connecting to imgcom.jsrt.or.jp (imgcom.jsrt.or.jp)|158.199.228.161|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14059498 (13M) [application/zip]\n",
            "Saving to: ‘autoencoder_img.zip’\n",
            "\n",
            "autoencoder_img.zip 100%[===================>]  13.41M  2.38MB/s    in 6.7s    \n",
            "\n",
            "2023-10-14 23:20:18 (2.01 MB/s) - ‘autoencoder_img.zip’ saved [14059498/14059498]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://imgcom.jsrt.or.jp/imgcom/wp-content/uploads/2019/07/autoencoder_img.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip autoencoder_img.zip"
      ],
      "metadata": {
        "id": "wi7oewOABef5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install anomalib"
      ],
      "metadata": {
        "id": "6mRy8-uTBvJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/openvinotoolkit/anomalib.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HR_v6j8XB4y0",
        "outputId": "4b347b31-912f-4c50-e2f3-11b1a3944a3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'anomalib'...\n",
            "remote: Enumerating objects: 31277, done.\u001b[K\n",
            "remote: Counting objects: 100% (1743/1743), done.\u001b[K\n",
            "remote: Compressing objects: 100% (994/994), done.\u001b[K\n",
            "remote: Total 31277 (delta 993), reused 1167 (delta 703), pack-reused 29534\u001b[K\n",
            "Receiving objects: 100% (31277/31277), 1.51 GiB | 24.69 MiB/s, done.\n",
            "Resolving deltas: 100% (17576/17576), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mipT4b1usVF8",
        "outputId": "4c872d4e-9f68-45b0-fd08-e5eb25ea28e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd anomalib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Rd8t2B2dn_9",
        "outputId": "7a0f12cb-4b0d-45c2-bcf1-c9607ca5250b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/anomalib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hxr7F0wxel5S",
        "outputId": "54d46411-b805-4197-9fe2-29f8fa5fe926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.15.12-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.37-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.0/190.0 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.32.0-py2.py3-none-any.whl (240 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.0/241.0 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting pathtools (from wandb)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=331befa748b9c9856358aa079c3595170124711339a505642ad9e62a58f75e6c\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.37 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.32.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.15.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install OpenVINO"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0SzZHYzerO1",
        "outputId": "b00a7db7-4f35-443e-c2d5-a4053dc7ecec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting OpenVINO\n",
            "  Downloading openvino-2023.1.0-12185-cp310-cp310-manylinux2014_x86_64.whl (35.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.2/35.2 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from OpenVINO) (1.23.5)\n",
            "Collecting openvino-telemetry>=2023.1.0 (from OpenVINO)\n",
            "  Downloading openvino_telemetry-2023.2.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: openvino-telemetry, OpenVINO\n",
            "Successfully installed OpenVINO-2023.1.0 openvino-telemetry-2023.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "folder_path = '/content/anomalib'\n",
        "\n",
        "try:\n",
        "    shutil.rmtree(folder_path)\n",
        "    print(f\"The folder '{folder_path}' and its contents have been successfully deleted.\")\n",
        "except OSError as e:\n",
        "    print(f\"Error: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykbkIP5jkVBn",
        "outputId": "3480b8a5-3983-4bbd-cbe3-32353a7249d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The folder '/content/anomalib' and its contents have been successfully deleted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset:\n",
        "#     name: autoen\n",
        "#     format: folder\n",
        "#     root: ./datasets\n",
        "#     normal_dir: normal # name of the folder containing normal images.\n",
        "#     abnormal_dir: flip # name of the folder containing abnormal images.\n",
        "#     task: classification # classification or segmentation\n",
        "#     mask_dir: null #optional\n",
        "#     normal_test_dir: null # optional\n",
        "#     extensions: null\n",
        "#     split_ratio: 0.2  # normal images ratio to create a test split\n",
        "#     seed: 0\n",
        "#     image_size: 256\n",
        "#     train_batch_size: 32\n",
        "#     eval_batch_size: 32\n",
        "#     num_workers: 8\n",
        "#     normalization: imagenet # data distribution to which the images will be normalized\n",
        "#     test_split_mode: from_dir # options [from_dir, synthetic]\n",
        "#     val_split_ratio: 0.5 # fraction of train/test images held out for validation (usage depends on val_split_mode)\n",
        "#     transform_config:\n",
        "#         train: null\n",
        "#         eval: null\n",
        "#     val_split_mode: from_test # determines how the validation set is created, options [same_as_test, from_test]\n",
        "#     tiling:\n",
        "#         apply: false\n",
        "#         tile_size: null\n",
        "#         stride: null\n",
        "#         remove_border_count: 0\n",
        "#         use_random_tiling: False\n",
        "#         random_tile_count: 16"
      ],
      "metadata": {
        "id": "pRojaxFSmw7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python tools/train.py --config src/anomalib/models/stfpm/config.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCcvEc09EFRI",
        "outputId": "afe582fb-7e2b-4a51-872d-cb9e6b4eb28a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/anomalib/config/config.py:243: UserWarning: The seed value is now fixed to 0. Up to v0.3.7, the seed was not fixed when the seed value was set to 0. If you want to use the random seed, please select `None` for the seed value (`null` in the YAML file) or remove the `seed` key from the YAML file.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/anomalib/config/config.py:280: UserWarning: config.project.unique_dir is set to False. This does not ensure that your results will be written in an empty directory and you may overwrite files.\n",
            "  warn(\n",
            "Global seed set to 0\n",
            "2023-10-15 00:32:41,548 - anomalib.data - INFO - Loading the datamodule\n",
            "2023-10-15 00:32:41,549 - anomalib.data.utils.transform - INFO - No config file has been provided. Using default transforms.\n",
            "2023-10-15 00:32:41,550 - anomalib.data.utils.transform - INFO - No config file has been provided. Using default transforms.\n",
            "2023-10-15 00:32:41,550 - anomalib.models - INFO - Loading the model.\n",
            "2023-10-15 00:32:41,551 - anomalib.models.components.base.anomaly_module - INFO - Initializing StfpmLightning model.\n",
            "/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `PrecisionRecallCurve` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "2023-10-15 00:32:41,560 - anomalib.models.components.feature_extractors.timm - WARNING - FeatureExtractor is deprecated. Use TimmFeatureExtractor instead. Both FeatureExtractor and TimmFeatureExtractor will be removed in a future release.\n",
            "2023-10-15 00:32:42,058 - timm.models.helpers - INFO - Loading pretrained weights from url (https://download.pytorch.org/models/resnet18-5c106cde.pth)\n",
            "2023-10-15 00:32:42,267 - anomalib.models.components.feature_extractors.timm - WARNING - FeatureExtractor is deprecated. Use TimmFeatureExtractor instead. Both FeatureExtractor and TimmFeatureExtractor will be removed in a future release.\n",
            "2023-10-15 00:32:42,669 - anomalib.utils.loggers - INFO - Loading the experiment logger(s)\n",
            "2023-10-15 00:32:42,670 - anomalib.utils.callbacks - INFO - Loading the callbacks\n",
            "/usr/local/lib/python3.10/dist-packages/anomalib/utils/callbacks/__init__.py:142: UserWarning: Export option: None not found. Defaulting to no model export\n",
            "  warnings.warn(f\"Export option: {config.optimization.export_mode} not found. Defaulting to no model export\")\n",
            "2023-10-15 00:32:42,718 - pytorch_lightning.utilities.rank_zero - INFO - GPU available: False, used: False\n",
            "2023-10-15 00:32:42,718 - pytorch_lightning.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores\n",
            "2023-10-15 00:32:42,719 - pytorch_lightning.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs\n",
            "2023-10-15 00:32:42,719 - pytorch_lightning.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs\n",
            "2023-10-15 00:32:42,719 - pytorch_lightning.utilities.rank_zero - INFO - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
            "2023-10-15 00:32:42,719 - pytorch_lightning.utilities.rank_zero - INFO - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "2023-10-15 00:32:42,719 - pytorch_lightning.utilities.rank_zero - INFO - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "2023-10-15 00:32:42,719 - pytorch_lightning.utilities.rank_zero - INFO - `Trainer(limit_predict_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "2023-10-15 00:32:42,719 - pytorch_lightning.utilities.rank_zero - INFO - `Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
            "2023-10-15 00:32:42,719 - anomalib - INFO - Training the model.\n",
            "2023-10-15 00:32:42,949 - anomalib.data.base.datamodule - INFO - No normal test images found. Sampling from training set using a split ratio of 0.20\n",
            "2023-10-15 00:32:42,959 - anomalib.utils.callbacks.metrics_configuration - WARNING - Cannot perform pixel-level evaluation when task type is classification. Ignoring the following pixel-level metrics: ['F1Score', 'AUROC']\n",
            "/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `ROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "2023-10-15 00:32:42,969 - pytorch_lightning.callbacks.model_summary - INFO - \n",
            "  | Name                  | Type                     | Params\n",
            "-------------------------------------------------------------------\n",
            "0 | image_threshold       | AnomalyScoreThreshold    | 0     \n",
            "1 | pixel_threshold       | AnomalyScoreThreshold    | 0     \n",
            "2 | model                 | STFPMModel               | 5.6 M \n",
            "3 | loss                  | STFPMLoss                | 0     \n",
            "4 | image_metrics         | AnomalibMetricCollection | 0     \n",
            "5 | pixel_metrics         | AnomalibMetricCollection | 0     \n",
            "6 | normalization_metrics | MinMax                   | 0     \n",
            "-------------------------------------------------------------------\n",
            "2.8 M     Trainable params\n",
            "2.8 M     Non-trainable params\n",
            "5.6 M     Total params\n",
            "22.262    Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch 0:   0% 0/3 [00:00<?, ?it/s] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('train_loss', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "  rank_zero_warn(\n",
            "Epoch 0:  33% 1/3 [00:11<00:23, 11.92s/it, loss=44.5, train_loss_step=44.50]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 0:  67% 2/3 [00:18<00:09,  9.42s/it, loss=44.5, train_loss_step=44.50]\n",
            "Epoch 0: 100% 3/3 [00:20<00:00,  6.82s/it, loss=44.5, train_loss_step=44.50, image_F1Score=0.919, image_AUROC=0.358]\n",
            "Epoch 1:  33% 1/3 [00:11<00:23, 11.75s/it, loss=40.5, train_loss_step=36.50, image_F1Score=0.919, image_AUROC=0.358, train_loss_epoch=44.50]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1:  67% 2/3 [00:18<00:09,  9.09s/it, loss=40.5, train_loss_step=36.50, image_F1Score=0.919, image_AUROC=0.358, train_loss_epoch=44.50]\n",
            "Epoch 1: 100% 3/3 [00:19<00:00,  6.55s/it, loss=40.5, train_loss_step=36.50, image_F1Score=0.919, image_AUROC=0.373, train_loss_epoch=44.50]\n",
            "Epoch 2:  33% 1/3 [00:10<00:21, 10.66s/it, loss=36.8, train_loss_step=29.30, image_F1Score=0.919, image_AUROC=0.373, train_loss_epoch=36.50]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2:  67% 2/3 [00:17<00:08,  8.86s/it, loss=36.8, train_loss_step=29.30, image_F1Score=0.919, image_AUROC=0.373, train_loss_epoch=36.50]\n",
            "Epoch 2: 100% 3/3 [00:19<00:00,  6.61s/it, loss=36.8, train_loss_step=29.30, image_F1Score=0.919, image_AUROC=0.490, train_loss_epoch=36.50]\n",
            "Epoch 3:  33% 1/3 [00:09<00:19,  9.69s/it, loss=33.8, train_loss_step=24.90, image_F1Score=0.919, image_AUROC=0.490, train_loss_epoch=29.30]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3:  67% 2/3 [00:17<00:08,  8.87s/it, loss=33.8, train_loss_step=24.90, image_F1Score=0.919, image_AUROC=0.490, train_loss_epoch=29.30]\n",
            "Epoch 3: 100% 3/3 [00:19<00:00,  6.60s/it, loss=33.8, train_loss_step=24.90, image_F1Score=0.932, image_AUROC=0.647, train_loss_epoch=29.30]\n",
            "Epoch 4:  33% 1/3 [00:08<00:17,  8.78s/it, loss=31.6, train_loss_step=22.70, image_F1Score=0.932, image_AUROC=0.647, train_loss_epoch=24.90]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 4:  67% 2/3 [00:18<00:09,  9.04s/it, loss=31.6, train_loss_step=22.70, image_F1Score=0.932, image_AUROC=0.647, train_loss_epoch=24.90]\n",
            "Epoch 4: 100% 3/3 [00:19<00:00,  6.65s/it, loss=31.6, train_loss_step=22.70, image_F1Score=0.932, image_AUROC=0.608, train_loss_epoch=24.90]\n",
            "Epoch 5:  33% 1/3 [00:17<00:35, 17.85s/it, loss=29.9, train_loss_step=21.40, image_F1Score=0.932, image_AUROC=0.608, train_loss_epoch=22.70]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 5:  67% 2/3 [00:24<00:12, 12.11s/it, loss=29.9, train_loss_step=21.40, image_F1Score=0.932, image_AUROC=0.608, train_loss_epoch=22.70]\n",
            "Epoch 5: 100% 3/3 [00:25<00:00,  8.59s/it, loss=29.9, train_loss_step=21.40, image_F1Score=0.932, image_AUROC=0.613, train_loss_epoch=22.70]\n",
            "Epoch 6:  33% 1/3 [00:11<00:22, 11.41s/it, loss=28.5, train_loss_step=20.50, image_F1Score=0.932, image_AUROC=0.613, train_loss_epoch=21.40]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 6:  67% 2/3 [00:17<00:08,  8.97s/it, loss=28.5, train_loss_step=20.50, image_F1Score=0.932, image_AUROC=0.613, train_loss_epoch=21.40]\n",
            "Epoch 6: 100% 3/3 [00:20<00:00,  6.70s/it, loss=28.5, train_loss_step=20.50, image_F1Score=0.932, image_AUROC=0.554, train_loss_epoch=21.40]\n",
            "Epoch 7:  33% 1/3 [00:10<00:20, 10.41s/it, loss=27.4, train_loss_step=19.60, image_F1Score=0.932, image_AUROC=0.554, train_loss_epoch=20.50]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 7:  67% 2/3 [00:18<00:09,  9.19s/it, loss=27.4, train_loss_step=19.60, image_F1Score=0.932, image_AUROC=0.554, train_loss_epoch=20.50]\n",
            "Epoch 7: 100% 3/3 [00:20<00:00,  6.80s/it, loss=27.4, train_loss_step=19.60, image_F1Score=0.919, image_AUROC=0.544, train_loss_epoch=20.50]\n",
            "Epoch 8:  33% 1/3 [00:08<00:17,  8.73s/it, loss=26.5, train_loss_step=18.80, image_F1Score=0.919, image_AUROC=0.544, train_loss_epoch=19.60]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 8:  67% 2/3 [00:17<00:08,  8.86s/it, loss=26.5, train_loss_step=18.80, image_F1Score=0.919, image_AUROC=0.544, train_loss_epoch=19.60]\n",
            "Epoch 8: 100% 3/3 [00:18<00:00,  6.32s/it, loss=26.5, train_loss_step=18.80, image_F1Score=0.919, image_AUROC=0.466, train_loss_epoch=19.60]\n",
            "Epoch 8: 100% 3/3 [00:18<00:00,  6.32s/it, loss=26.5, train_loss_step=18.80, image_F1Score=0.919, image_AUROC=0.466, train_loss_epoch=18.80]\n",
            "2023-10-15 00:35:49,008 - anomalib.utils.callbacks.timer - INFO - Training took 186.04 seconds\n",
            "2023-10-15 00:35:49,008 - anomalib - INFO - Loading the best model weights.\n",
            "2023-10-15 00:35:49,009 - anomalib - INFO - Testing the model.\n",
            "2023-10-15 00:35:49,017 - pytorch_lightning.utilities.rank_zero - INFO - The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: EarlyStopping\n",
            "2023-10-15 00:35:49,018 - anomalib.utils.callbacks.model_loader - INFO - Loading the model from /content/anomalib/results/stfpm/autoen/run/weights/lightning/model.ckpt\n",
            "2023-10-15 00:35:49,077 - anomalib.utils.callbacks.metrics_configuration - WARNING - Cannot perform pixel-level evaluation when task type is classification. Ignoring the following pixel-level metrics: ['F1Score', 'AUROC']\n",
            "Testing DataLoader 0: 100% 2/2 [00:15<00:00,  7.88s/it]2023-10-15 00:36:05,226 - anomalib.utils.callbacks.timer - INFO - Testing took 16.141793251037598 seconds\n",
            "Throughput (batch_size=32) : 2.4780394208945027 FPS\n",
            "Testing DataLoader 0: 100% 2/2 [00:15<00:00,  7.96s/it]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m       image_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6470588445663452    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m      image_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9315068125724792    \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python tools/train.py --config src/anomalib/models/stfpm/config.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOqmI2MRoIml",
        "outputId": "bd3ce497-756e-46db-d75b-23ac1447cd6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/anomalib/config/config.py:243: UserWarning: The seed value is now fixed to 0. Up to v0.3.7, the seed was not fixed when the seed value was set to 0. If you want to use the random seed, please select `None` for the seed value (`null` in the YAML file) or remove the `seed` key from the YAML file.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/anomalib/config/config.py:280: UserWarning: config.project.unique_dir is set to False. This does not ensure that your results will be written in an empty directory and you may overwrite files.\n",
            "  warn(\n",
            "Global seed set to 0\n",
            "2023-10-15 00:12:33,091 - anomalib.data - INFO - Loading the datamodule\n",
            "2023-10-15 00:12:33,092 - anomalib.data.utils.transform - INFO - Loading transforms from config File\n",
            "2023-10-15 00:12:33,092 - anomalib.data.utils.transform - INFO - Transform Resize(always_apply=False, p=1, height=512, width=512, interpolation=1) added!\n",
            "2023-10-15 00:12:33,092 - anomalib.data.utils.transform - INFO - Transform HorizontalFlip(always_apply=False, p=0.5) added!\n",
            "2023-10-15 00:12:33,093 - anomalib.data.utils.transform - INFO - Transform RandomBrightnessContrast(always_apply=False, p=0.5, brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), brightness_by_max=True) added!\n",
            "2023-10-15 00:12:33,093 - anomalib.data.utils.transform - INFO - Transform Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0) added!\n",
            "2023-10-15 00:12:33,094 - anomalib.data.utils.transform - INFO - Loading transforms from config File\n",
            "2023-10-15 00:12:33,094 - anomalib.data.utils.transform - INFO - Transform Resize(always_apply=False, p=1, height=512, width=512, interpolation=1) added!\n",
            "2023-10-15 00:12:33,094 - anomalib.data.utils.transform - INFO - Transform Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0) added!\n",
            "2023-10-15 00:12:33,094 - anomalib.models - INFO - Loading the model.\n",
            "2023-10-15 00:12:33,095 - anomalib.models.components.base.anomaly_module - INFO - Initializing StfpmLightning model.\n",
            "/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `PrecisionRecallCurve` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "2023-10-15 00:12:33,118 - anomalib.models.components.feature_extractors.timm - WARNING - FeatureExtractor is deprecated. Use TimmFeatureExtractor instead. Both FeatureExtractor and TimmFeatureExtractor will be removed in a future release.\n",
            "2023-10-15 00:12:34,031 - timm.models.helpers - INFO - Loading pretrained weights from url (https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rsb-weights/resnet50_a1_0-14fe96d1.pth)\n",
            "2023-10-15 00:12:34,610 - anomalib.models.components.feature_extractors.timm - WARNING - FeatureExtractor is deprecated. Use TimmFeatureExtractor instead. Both FeatureExtractor and TimmFeatureExtractor will be removed in a future release.\n",
            "2023-10-15 00:12:35,541 - anomalib.utils.loggers - INFO - Loading the experiment logger(s)\n",
            "2023-10-15 00:12:35,542 - anomalib.utils.callbacks - INFO - Loading the callbacks\n",
            "/usr/local/lib/python3.10/dist-packages/anomalib/utils/callbacks/__init__.py:142: UserWarning: Export option: None not found. Defaulting to no model export\n",
            "  warnings.warn(f\"Export option: {config.optimization.export_mode} not found. Defaulting to no model export\")\n",
            "2023-10-15 00:12:35,603 - pytorch_lightning.utilities.rank_zero - INFO - GPU available: False, used: False\n",
            "2023-10-15 00:12:35,603 - pytorch_lightning.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores\n",
            "2023-10-15 00:12:35,603 - pytorch_lightning.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs\n",
            "2023-10-15 00:12:35,603 - pytorch_lightning.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs\n",
            "2023-10-15 00:12:35,603 - pytorch_lightning.utilities.rank_zero - INFO - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
            "2023-10-15 00:12:35,603 - pytorch_lightning.utilities.rank_zero - INFO - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "2023-10-15 00:12:35,604 - pytorch_lightning.utilities.rank_zero - INFO - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "2023-10-15 00:12:35,604 - pytorch_lightning.utilities.rank_zero - INFO - `Trainer(limit_predict_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "2023-10-15 00:12:35,604 - pytorch_lightning.utilities.rank_zero - INFO - `Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
            "2023-10-15 00:12:35,604 - anomalib - INFO - Training the model.\n",
            "2023-10-15 00:12:35,888 - anomalib.data.base.datamodule - INFO - No normal test images found. Sampling from training set using a split ratio of 0.20\n",
            "2023-10-15 00:12:35,896 - anomalib.utils.callbacks.metrics_configuration - WARNING - Cannot perform pixel-level evaluation when task type is classification. Ignoring the following pixel-level metrics: ['F1Score', 'AUROC']\n",
            "/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `ROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "2023-10-15 00:12:35,919 - pytorch_lightning.callbacks.model_summary - INFO - \n",
            "  | Name                  | Type                     | Params\n",
            "-------------------------------------------------------------------\n",
            "0 | image_threshold       | AnomalyScoreThreshold    | 0     \n",
            "1 | pixel_threshold       | AnomalyScoreThreshold    | 0     \n",
            "2 | model                 | STFPMModel               | 17.1 M\n",
            "3 | loss                  | STFPMLoss                | 0     \n",
            "4 | image_metrics         | AnomalibMetricCollection | 0     \n",
            "5 | pixel_metrics         | AnomalibMetricCollection | 0     \n",
            "6 | normalization_metrics | MinMax                   | 0     \n",
            "-------------------------------------------------------------------\n",
            "8.5 M     Trainable params\n",
            "8.5 M     Non-trainable params\n",
            "17.1 M    Total params\n",
            "68.346    Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch 0:   0% 0/2 [00:00<?, ?it/s] ^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python tools/train.py --config src/anomalib/models/stfpm/config.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApHSTlvLmTaX",
        "outputId": "820fc2b9-63cd-48f6-9c2e-fc456258fc17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 153, in _path_is_mode_type\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 147, in _path_stat\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/usr/local/lib/python3.10/dist-packages/torch/ao/quantization/__init__.cpython-310-x86_64-linux-gnu.so'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/anomalib/tools/train.py\", line 15, in <module>\n",
            "    from pytorch_lightning import Trainer, seed_everything\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/__init__.py\", line 34, in <module>\n",
            "    from lightning_fabric.utilities.seed import seed_everything  # noqa: E402\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning_fabric/__init__.py\", line 23, in <module>\n",
            "    from lightning_fabric.fabric import Fabric  # noqa: E402\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning_fabric/fabric.py\", line 21, in <module>\n",
            "    import torch\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/__init__.py\", line 1285, in <module>\n",
            "    from torch import quantization as quantization\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/quantization/__init__.py\", line 1, in <module>\n",
            "    from .quantize import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/quantization/quantize.py\", line 10, in <module>\n",
            "    from torch.ao.quantization.quantize import _convert\n",
            "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1002, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 945, in _find_spec\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1439, in find_spec\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1411, in _get_spec\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1563, in find_spec\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 161, in _path_isfile\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 153, in _path_is_mode_type\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To get help about the arguments, run\n",
        "!python tools/inference/lightning_inference.py \\\n",
        "    --config src/anomalib/models/stfpm/config.yaml \\\n",
        "    --weights results/stfpm/autoen/run/weights/lightning/model.ckpt \\\n",
        "    --input datasets/flip/case231.bmp\\\n",
        "    --output results/stfpm/autoen/bottle/images"
      ],
      "metadata": {
        "id": "Z4smCBTdHbix",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "313806bc-7203-4445-8e9c-dbc19a749959"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/anomalib/config/config.py:243: UserWarning: The seed value is now fixed to 0. Up to v0.3.7, the seed was not fixed when the seed value was set to 0. If you want to use the random seed, please select `None` for the seed value (`null` in the YAML file) or remove the `seed` key from the YAML file.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/anomalib/config/config.py:280: UserWarning: config.project.unique_dir is set to False. This does not ensure that your results will be written in an empty directory and you may overwrite files.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `PrecisionRecallCurve` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "FeatureExtractor is deprecated. Use TimmFeatureExtractor instead. Both FeatureExtractor and TimmFeatureExtractor will be removed in a future release.\n",
            "FeatureExtractor is deprecated. Use TimmFeatureExtractor instead. Both FeatureExtractor and TimmFeatureExtractor will be removed in a future release.\n",
            "/usr/local/lib/python3.10/dist-packages/anomalib/utils/callbacks/__init__.py:142: UserWarning: Export option: None not found. Defaulting to no model export\n",
            "  warnings.warn(f\"Export option: {config.optimization.export_mode} not found. Defaulting to no model export\")\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:55: LightningDeprecationWarning: Setting `Trainer(resume_from_checkpoint=)` is deprecated in v1.5 and will be removed in v2.0. Please pass `Trainer.fit(ckpt_path=)` directly instead.\n",
            "  rank_zero_deprecation(\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
            "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "`Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "`Trainer(limit_predict_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
            "Missing logger folder: results/stfpm/autoen/run/lightning_logs\n",
            "Cannot perform pixel-level evaluation when task type is classification. Ignoring the following pixel-level metrics: ['F1Score', 'AUROC']\n",
            "/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `ROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "2023-10-15 00:45:31.900780: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-10-15 00:45:34.822946: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Predicting DataLoader 0: 100% 1/1 [00:00<00:00,  5.25it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JQaPcRn6y2y_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}